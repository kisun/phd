\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{xfrac}

\usepackage{fullpage}
\usepackage{parskip}


<<echo=FALSE,results="hide",messages=FALSE,echo=FALSE>>=
opts_chunk$set(fig.width=8,fig.height=5,fig.align="center")
suppressMessages({
    library(mvtnorm)
    library(RSQLite)
})
@ 

\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\bu}{\boldsymbol{u}}
\newcommand{\bw}{\boldsymbol{w}}
\newcommand{\bz}{\boldsymbol{z}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\bY}{\boldsymbol{Y}}
\newcommand{\br}{\boldsymbol{r}}
\newcommand{\bs}{\boldsymbol{s}}
\newcommand{\bh}{\boldsymbol{h}}
\newcommand{\bv}{\boldsymbol{v}}
\newcommand{\bfn}{\boldsymbol{f}}
\newcommand{\bF}{\boldsymbol{F}}
\newcommand{\bg}{\boldsymbol{g}}
\newcommand{\bH}{\boldsymbol{2H}}
\newcommand{\bK}{\boldsymbol{K}}
\newcommand{\bQ}{\boldsymbol{Q}}
\newcommand{\bR}{\boldsymbol{R}}
\newcommand{\bP}{\boldsymbol{P}}
\newcommand{\bS}{\boldsymbol{S}}
\newcommand{\bZero}{\boldsymbol{0}}
\newcommand{\dd}[2]{\frac{\partial {#1}}{\partial {#2}}}

\newcommand{\X}{\mathrm{X}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\V}{\mathrm{V}}


\newcommand{\pr}{\mathbb{P}}
\renewcommand{\Pr}[1]{\pr\left(#1\right)}


\newcommand{\km}{_{k-1}}
\newcommand{\kk}{_{k|k}}
\newcommand{\kkm}{_{k|k-1}}
\newcommand{\kmkm}{_{k-1|k-1}}


\title{Particle Filter}
\author{Exploration}
\date{}

\begin{document}
\maketitle


\section{Trajectory Constrained to ``Road''}


We propose a two-stage algorithm that involves several different aspects:

\begin{itemize}
\item GPS location: this is a vector $\by = \left[p_{\mathrm{lat}}, p_{\mathrm{lon}}\right]^T$; we
  must also take into account GPS error (which is typically known, and can at least be estimated).
  

\item Route information: we know where the bus will be going, which reduced the 2-dimentional
  problem down to 1; we need to switch between $\by$ and $d = $ distance into trip.
\end{itemize}


We will be using the following system model, where, at time $k \in 1,\ldots,K$, 
\begin{itemize}
\item 
  $\bx_k$ is the state $\left[d_k, v_k\right]^T$ (= distance-into-trip and velocity, respectively)
  
\item
  $f_k$ is the (assumed known) system transition function, 
  
\item
  $\bu_k$ are the control variables $\left[t_k, \Delta_k\right]^T$ (= time in seconds and time between
  observations, respectively), and
  
\item
  $\bw_k$ is a zero-mean white noise with known distribution $p(\bw_k)$,
  
\end{itemize}
which leads us to:
\begin{equation}
  \label{eq:state_model1}
  \bx_k = 
  f_k\left(\bx_k, \bu_k\right) + \bw_k.
\end{equation}

The second part is the observation equation, which consists of
\begin{itemize}
\item 
  $\by_k$, the observations (GPS coordinates),

\item 
  $h_k$, the measurement function, and

\item 
  $v_k$, the zero-mean, white system noise (e.g., GPS error, \ldots),
\end{itemize}
which come together to give us
\begin{equation}
  \label{eq:state_model2}
  \by_k = 
  h_k\left(\hat\bx_k\right) + \bv_k.
\end{equation}
In our case, $h_k = h$ will map distance-into-trip values to GPS coordinates.
The reason for converting between distance and GPS is to help overcome potential issues that will
arise for example when routes do a ``loop''.


\subsection{Example 1: Straight Trajectory}

In this first example, the ``route'' will be a straight line, observations will be evenly
distributed (i.e., $\Delta_k = \Delta = 1$ for simplicity), and we will use a simple first order
dynamics equation, where $\bw_k$ is the unknown accelaration,
\begin{equation}
  \label{eq:simple_dynamics}
  \bx_k = A\bx_{k-1} + Gw_k,
\end{equation}
where 
$A =
\begin{bmatrix}
  1 & \Delta \\ 0 & 1
\end{bmatrix}$ and 
$G =
\begin{bmatrix}
  \frac{\Delta^2}{2} \\ \Delta
\end{bmatrix}$.
We can later complicate it.

The next part is the mapping from distance to GPS. We will have a single path (with known bearing $\Psi$), so we
can for now get away with (remembering that $d_k = \bx_{1k}$):
\begin{equation}
  \label{eq:d_to_gps}
  h\left(\hat \bx_k\right) = 
  d_k \begin{bmatrix}
    \sin \Psi \\ \cos \Psi
  \end{bmatrix}
\end{equation}


\subsubsection{Simulation Setup}

The ``route'' will start from the origin and end at $\left(20, 15\right)$,
which gives the bearing $\Psi = \tan^{-1}\left(\frac{20}{15}\right)$. 
We then take observations at times $t \in 1, \ldots, 5$~(s), with a constant speed of 3~ms$^{-1}$ from beginning to
end, and ``GPS error'' of 0.5~(m). Thus, the actual positions and simulated observations are:
<<true_positions,cache=TRUE>>=
set.seed(345346)
Psi <- atan(20/15)
h <- function(x) x[1] * rbind(sin(Psi), cos(Psi))
t <- 1:5
Xtrue <- rbind(t * 3, 3)
Ytrue <- apply(Xtrue, 2, h)
y <- round(Ytrue + t(rmvnorm(length(t), sigma = diag(c(0.5, 0.5)))), 4)

theplot <- function() {
    plot(y[1, ], y[2, ], pch = 19, xlim = c(0, 20), ylim = c(-2, 15), asp = 1,
         xlab = expression(p[lon]), ylab = expression(p[lat]))
    abline(h = 0, v = 0, lty = 3)
    lines(c(0, 20), c(0, 15), lty = 2)
    points(Ytrue[1, ], Ytrue[2, ], pch = 19, cex = 0.3, col = "red")
}
theplot()
@ 


\subsubsection{Simulation Results}

We need a prior distribution on the initial position, which is infact known exactly, however the
speed is unknown:
\begin{equation}
  \label{eq:prior}
  x_0 \sim \mathcal{N}\left(
    \begin{bmatrix}
      0 \\ v_0
    \end{bmatrix},
    \begin{bmatrix}
      0 & 0 \\
      0 & 5
    \end{bmatrix}
  \right),\quad v_0 = 5.
\end{equation}



<<run_pf,cache=TRUE>>=
lhood <- function(y, x)
    dmvnorm(y, h(x), diag(c(1, 1)))
pw <- function(n)
    rnorm(n, 0, 0.2)
Delta <- 1
A <- cbind(c(1, 0), c(Delta, 1))
G <- rbind(Delta^2/2, Delta)
fn <- function(x, w)
    structure(A %*% x + G %*% w, .Dimnames = list(c("distance", "speed"), NULL))

N <- 200
x0 <- t(rmvnorm(N, c(0, 5), diag(c(0, 5))))
theplot()

x1hat <- fn(x0, pw(N))
hx1hat <- apply(x1hat, 2, h)
points(hx1hat[1, ], hx1hat[2, ], pch = 3, col = "#00009970")

weights <- apply(x1hat, 2, function(xi) lhood(y[, 1], xi))
qi <- weights / sum(weights)
ii <- sample(N, N, TRUE, qi)
x1 <- x1hat[, ii]

hx1 <- apply(x1, 2, h)
points(hx1[1, ], hx1[2, ], pch = 19, col = "#00990040", cex = 0.5)
points(Ytrue[1, ], Ytrue[2, ], pch = 19, cex = 0.3, col = "red")
@ 


Now for the rest of them \ldots

<<run_pf_loop,fig.width=16,fig.height=10,cache=TRUE>>=
par(mfrow = c(2, 2))
xx <- x1
M <- length(t)
xxhat.hist <- xx.hist <- array(NA, c(2, N, M))
xxhat.hist[,,1] <- x1hat
xx.hist[,,1] <- x1
for (i in t[-1]) {
    xxhat.hist[,,i] <- xxhat <- fn(xx, pw(N))
    weights <- apply(xxhat, 2, function(xi) lhood(y[, i], xi))
    qi <- weights / sum(weights)
    ii <- sample(N, N, TRUE, qi)
    xx.hist[,,i] <- xx <- xxhat[, ii]
    
    hxxhat <- apply(xxhat, 2, h)
    hxx <- apply(xx, 2, h)
    
    theplot()
    points(hxxhat[1, ], hxxhat[2, ], pch = 3, col = "#00009070")
    points(hxx[1, ], hxx[2, ], pch = 19, col = "#00990040", cex = 0.5)
    points(y[1, ], y[2, ], pch = 19)
    points(Ytrue[1, i], Ytrue[2, i], pch = 19, cex = 0.6, col = "red")
}

rowMeans(xx)
@ 

<<dist_speed_plots>>=
plot(NA, xlim = range(xxhat.hist[1,,]), ylim = range(xxhat.hist[2,,]),
     xlab = "Distance (m)", ylab = "Speed (m/s)")
cols <- rainbow(M)
colsa <- rainbow(M, alpha = 0.1)
invisible(
    sapply(t, function(ti) {
               points(xxhat.hist[1,,ti], xxhat.hist[2,,ti], pch = 19, col = colsa[ti])
               points(xx.hist[1,,ti], xx.hist[2,,ti], pch = 19, col = cols[ti], cex = 0.3)
           })
    )

@ 



\subsection{Example 2: A Road with Corners}

We will now construct an artifical road that is made up of several segments. Here's the road:

<<road_segments>>=
px <- c(0, 5, 7, 3, -2, -4)
py <- c(0, 3, 6, 8, 7, 2)
road <- function() {
    plot(px, py, type = "l", lty = 2, xlim = c(0, 10), ylim = c(-5, 10), asp = 1,
         xlab = expression(p[lon]), ylab = expression(p[lat]))
    abline(h = 0, v = 0, lty = 3)
}
road()
@ 

Currently, we are \emph{not} using real GPS coordinates, so we don't yet have to worry about
scaling; therefore, we will use simple Euclidean distances to compute the (cumulative) length of
each line segment.

We then take observations at times $t \in 1,\ldots,5$ (s), of a ``vehicle'' travelling at 3~ms$^{-1}$,
again with a ``GPS error'' of 0.5~(m).

<<road_lengths>>=
shape <- data.frame(lon = px, lat = py,
                    distance = c(0, cumsum(sqrt(diff(px)^2 + diff(py)^2))))
shape$distance
@ 

The problem now is converting from distance to cartesian (GPS). This will involve an algorithm of
two steps:
\begin{enumerate}
\item 
  Find the ``point'', $\br_j$, in the shape set that has the smallest positive difference from the
  ``observed'' distance, $d_k$;

\item 
  Calculate the distance into the segment $\bs_j = \overrightarrow{\br_{j}\br_{j+1}} = \br_{j+1}
  - \br_j$, and the bearing of the segment, to calcualte the GPS position of the observation:
  \begin{equation}
    \label{eq:bearing_calc}
    \Psi_j = 
    \begin{cases}
      \tan^{-1} \frac{s_{j1}}{s_{j2}}, & r_{j1} >= 0, \\
      360 - \tan^{-1} \frac{s_{j1}}{s_{j2}}, & r_{j1} < 0.
    \end{cases}
  \end{equation}
  
  \begin{equation}
    \label{eq:converstion_formula}
    h_j\left(\hat\bx_k\right) = d_k 
    \begin{bmatrix}
      \sin \Psi_j \\ \cos \Psi_j
    \end{bmatrix}.
  \end{equation}
  
  The subscripts are: $j$ for the segment identification, each which has its own bearing and length,
  and $k$ for the observations (multiple observations can belong to the same segment---useful for
  reducing computations).
  
\end{enumerate}

For the most part, this can be added to the database;
<<segment_stuff,cache=TRUE>>=
shape$length <- c(sqrt(diff(px)^2 + diff(py)^2), NA)
theta <- 2 * pi - (atan2(diff(py), diff(px)) - pi / 2)
shape$bearing <- c(theta - 2 * pi * (theta >= 2 * pi), NA)
shape

h <- function(x, shape) {
    if (x[1] <= 0) return(c(0, 0))
    if (x[1] >= max(shape$distance)) return(as.numeric(shape[nrow(shape), 1:2]))
    
    j <- which.min(x[1] > shape$distance) - 1
    sj <- shape[j, ]
    Psi <- sj$bearing
    d <- x[1] - sj$distance
    as.numeric(sj[1:2]) + d * c(sin(Psi), cos(Psi))
}

Ytrue <- apply(Xtrue, 2, h, shape = shape)
y <- round(Ytrue + t(rmvnorm(length(t), sigma = diag(c(0.5, 0.5)))), 4)

theplot2 <- function() {
    road()
    points(y[1, ], y[2, ], pch = 19)
    points(Ytrue[1, ], Ytrue[2, ], pch = 19, cex = 0.3, col = "red")
}
theplot2()
@ 

Other than the above, everything else is basically the same!

<<results_ex2,cache=TRUE>>=
lhood <- function(y, x, shape)
    dmvnorm(y, h(x, shape), diag(c(1, 1)))

N <- 200
x0 <- t(rmvnorm(N, c(0, 5), diag(c(0, 5))))
theplot2()

x1hat <- fn(x0, pw(N))
hx1hat <- apply(x1hat, 2, h, shape = shape)
points(hx1hat[1, ], hx1hat[2, ], pch = 3, col = "#00009970")

weights <- apply(x1hat, 2, function(xi) lhood(y[, 1], xi, shape))
qi <- weights / sum(weights)
ii <- sample(N, N, TRUE, qi)
x1 <- x1hat[, ii]

hx1 <- apply(x1, 2, h, shape = shape)
points(hx1[1, ], hx1[2, ], pch = 19, col = "#00990040", cex = 0.5)
points(Ytrue[1, ], Ytrue[2, ], pch = 19, cex = 0.3, col = "red")
@ 

That look wonderful! Now for the rest \ldots

<<run_pf_loop2,fig.width=6,fig.height=10,out.width="0.6\\textwidth",cache=TRUE>>=
par(mfrow = c(4, 1))
xx <- x1
M <- length(t)
xxhat.hist <- xx.hist <- array(NA, c(2, N, M))
xxhat.hist[,,1] <- x1hat
xx.hist[,,1] <- x1
for (i in t[-1]) {
    xxhat.hist[,,i] <- xxhat <- fn(xx, pw(N))
    weights <- apply(xxhat, 2, function(xi) lhood(y[, i], xi, shape))
    qi <- weights / sum(weights)
    ii <- sample(N, N, TRUE, qi)
    xx.hist[,,i] <- xx <- xxhat[, ii]
    
    hxxhat <- apply(xxhat, 2, h, shape = shape)
    hxx <- apply(xx, 2, h, shape = shape)
    theplot2()
    points(hxxhat[1, ], hxxhat[2, ], pch = 3, col = "#00009070")
    points(hxx[1, ], hxx[2, ], pch = 19, col = "#00990040", cex = 0.5)
    points(y[1, ], y[2, ], pch = 19)
    points(Ytrue[1, i], Ytrue[2, i], pch = 19, cex = 0.6, col = "red")
}

rowMeans(xx)
@ 


That's essentially it! The only part missing is how to work with GPS coordinates (instead of
cartesian as in the examples).


\section{GPS Coordinates}

GPS coordinates are angles from the center of the Earth to points above/below the equator (latitude),
and points east/west of the Prime Meridian in Greenwich, England (longitude). However, the relative
scale between latitude and longitude, unlike the examples above, is not 1:1.
Even more, it is not constant across latitudes.
We must therefore transform GPS coordinates so the variances in lon/lat are equal on the ground.


\subsection{A GPS Route}

We'll take a route from Auckland Transport Static GTFS data.
<<AT_route>>=
con <- dbConnect(SQLite(), "gtfs.db")
plotShape <- function(id, conn = con) {
    sh <- dbGetQuery(conn, sprintf("SELECT shape_pt_lon AS lon, shape_pt_lat AS lat
                                   FROM shapes WHERE shape_id='%s'", id))
    plot(sh$lon, sh$lat, type = "l", asp = 1,
         xlab = "Longitude", ylab = "Latitude")
    points(sh$lon[1], sh$lat[1], pch = 19)
    invisible(sh)
}

shapeIDs <- dbGetQuery(con, "SELECT DISTINCT shape_id FROM shapes")
shape1 <- plotShape(shapeIDs[1, 1], con)
@ 

\subsubsection{GPS Distances}

Now let's say, for example, we have a GPS position for a bus of $\by = [174.78525, -36.84914]^T$.
We want to compare the \emph{distance} of this observation to the positions of the proposed particles.
Let's---for simplicity---assume that we ``uniformly'' place particles at every intersection (i.e.,
each shape point; we can figure out an algorithm to project them between points later).
It therefore seems logical to center all of the particles' coordinates, 
$\bz_i = h(\bx_i)$, on the observation $\by$, and compute
the distances, $e_i$, using a flat-earth approximation (any discrepancies will be minimal due to the small
distances between points). That is, the \emph{equirectangular projection}.
This uses Earth's radius $R = 6371000$~m, along with all values converted to \emph{radians}:
$\by^{\mathrm{rad}} = \frac{\pi}{180}\by = \left(\lambda_y, \phi_y\right)$ and
$\bz_i^{\mathrm{rad}} = \frac{\pi}{180}\bz_i = \left(\lambda_{z_i}, \phi_{z_i}\right)$.
\begin{align*}
  a_i &= \left( \lambda_y - \lambda_{z_{i}} \right) \cos\left(0.5\left(\phi_y + \phi_{z_i}\right)\right) \\
  &= \Delta\lambda \cos\left(0.5\left(\phi_y + \phi_{z_i}\right)\right) \\
  b_i &= \phi_y - \phi_{z_i} = \Delta\phi \\
  e_i &= R \sqrt{a^2 + b^2},
\end{align*}
the distance in whatever units $R$ is.
This can of course be vectorised fairly easily:
<<flat_earth_fn>>=
distanceFlat <- function(y, z, R = 6371000) {
    ## computes the distance between {y} and {z}
    ## different R (such as in km) give results in those units
    if (length(dim(y)) < 2)
        y <- cbind(y)
    if (length(dim(z)) < 2)
        z <- cbind(z)
    if (ncol(y) != ncol(z) & ncol(y) > 1 & ncol(z) > 1)
        stop("Incorrent dimensions")
    
    ## need to scale from degrees to radians:
    lam.y <- y[1, ] * pi / 180
    lam.z <- z[1, ] * pi / 180
    phi.y <- y[2, ] * pi / 180
    phi.z <- z[2, ] * pi / 180
    R * sqrt(((lam.y - lam.z) * cos(0.5 * (phi.y + phi.z)))^2 + (phi.y - phi.z)^2)
}
y <- c(174.78525, -36.84914)
z <- t(shape1)
distanceFlat(y, z)
@ 


\subsubsection{Route Distances}

We can also use the equirectangular projection to compute the length of each segment in the route
path, which we can use to determine distance into trip.
We will compute bearings in the next part.

<<route_distances>>=
# "from" 1->2, 2->3, 3->4, ..., (n-1)->n
y <- z[, -ncol(z)]
z <- z[, -1]
di <- distanceFlat(y, z)
shape1$distance <- c(0, cumsum(di))
shape1$length <- c(di, NA)
shape1[c(1:3, 23:25), ]
@ 

Well, that was easy.

\subsubsection{Route Bearings}

The next part is a little less simple, as the ``bearing'' changes as you move around the Earth in a
straight line.
Not that it will change much over a few hundred meters, we will use the initial bearing, $\theta^\circ$.
This will be used in the next step when we compute the position given a starting point, bearing, and
a distance traveled. 

Here we compute the initial bearing along segment a segment $\vec{ab}$,
$(\phi_a, \lambda_a)$ to $(\phi_b, \lambda_b)$ (again, in radians not degrees).
Also, $\Delta\lambda = \lambda_b - \lambda_a$.
\begin{align}
  \label{eq:bearing_comp}
  \theta^{\mathrm{rad}} &= 
  \mathrm{atan2}\left(\sin\Delta\lambda \cos\phi_b, 
           \cos\phi_a \sin\phi_b - \sin\phi_a \cos\phi_b \cos\Delta\lambda\right) \\
  \theta^\star &= \frac{180}{\pi}\theta^{\mathrm{rad}} \in \left[-180,180\right) \\
  \theta^\circ &= \left(\theta^\star + 180\right) \mod 360 \in \left[0,360\right)
\end{align}

<<calc_bearings>>=
bearing <- function(a, b) {
    if (length(dim(a)) < 2) y <- cbind(a)
    if (length(dim(b)) < 2) z <- cbind(b)
    if (ncol(a) != ncol(b) & ncol(a) > 1 & ncol(b) > 1)
        stop("Incorrent dimensions")
    
    ## convert to radians!!
    lam.a <- a[1, ] * pi / 180
    lam.b <- b[1, ] * pi / 180
    phi.a <- a[2, ] * pi / 180
    phi.b <- b[2, ] * pi / 180
    
    th.rad <- atan2(sin(lam.b - lam.a) * cos(phi.b),
                    cos(phi.a) * sin(phi.b) - sin(phi.a) * cos(phi.b) * cos(lam.b - lam.a))
    (th.rad * 180 / pi) %% 360
}
shape1$bearing <- c(bearing(y, z), NA)
head(shape1)
@ 

That was also nice and easy! Well, only because we didn't have to figure out the formula!


\subsubsection{Coordinates of Distance into Segment}

Previously, we used basic trigonometry to figure out the $(X,Y)$ location mid-segment. That doesn't
apply now that we are moving between GPS coordinates.
Fortunately, someone smart figured out the formula for us.

The GPS coordinates of a particle, $\bz^{\mathrm{rad}} = (\lambda_z, \phi_z)$ 
(in radians, dropping the $i$ subscript for simplicity), that travels a
distance of $d$~m from the point $\bs = (\lambda_s, \phi_s)$ (in radians) at an initial bearing of $\theta^\circ$
is calcualted as follows.
We use the angle in radians, $\theta = \frac{\pi}{180}\theta^\circ$,
and the distance in radians, $\delta = \frac{d}{R}$ ($R$ is the Earth's radius, in the same units
and $d$).
\begin{align*}
  \phi_z &= 
  \sin^{-1}\left(
    \sin\phi_s \cos\delta + \cos\phi_s \sin\delta \cos\theta
  \right) \\
  \lambda_z &=
  \lambda_s + \mathrm{atan2}\left(
    \sin\theta \sin\delta \cos\phi_s,
    \cos\delta - \sin\phi_s \sin\phi_z
  \right)
\end{align*}

Looks simple enough, let's use it. Let's say we are 3000~m into the trip:
<<distance_into_trip_calc>>=
partialSegment <- function(x, theta, d, R = 6371000) {
    delta <- d / R ## for single calculation
    theta <- theta * pi / 180  ## convert to radians
    phi.s <- x[2] * pi / 180
    lam.s <- x[1] * pi / 180
    
    phi.z <- asin(sin(phi.s) * cos(delta) + cos(phi.s) * sin(delta) * cos(theta))
    lam.z <- lam.s + atan2(sin(theta) * sin(delta) * cos(phi.s),
                           cos(delta) - sin(phi.s) * sin(phi.z))
    c(lam.z, phi.z) * 180 / pi
}
h <- function(x, shape) {
    if (x[1] <= 0) return(c(0, 0))
    if (x[1] > max(shape$distance)) return(as.numeric(shape[nrow(shape), 1:2]))
    
    j <- which.min(x[1] > shape$distance) - 1
    sj <- shape[j, ]
    Psi <- sj$bearing
    d <- x[1] - sj$distance
    
    ## only do the calculations if we need to!
    if (d == 0) return(as.numeric(sj[1:2]))
    partialSegment(as.numeric(sj[1:2]), Psi, d)
}
x <- c(3000, NA)
z <- h(x, shape1)
plotShape(shapeIDs[1, 1], con)
points(shape1$lon, shape1$lat, cex = 0.4, pch = 19)
points(z[1], z[2], col = "red", pch = 4, cex = 0.6)
@ 

Hopefully this will be all we need for the following applications. We also make no assumptions about
location, so it should be transferable between cities, countries, and continents.


\section{Mock GTFS Realtime Data}

The next step is to create some mock data (i.e., bus locations at a sequence of time
points).  In the first few sections, we used equal time differences, so it makes sense to
first apply our model using evenly spaced time points. We will do this in two stages:
\begin{enumerate}
\item 
  using a constant speed function (essentially the same as the previous simulation), and
  
  
\item 
  using the schedule data and fit a smooth polynomial through this, the derivative of
  which will give us scheduled speed.
\end{enumerate}
Both will use the same route as used above.


\subsection{Constant Speed}

We will assume the bus travels at a \emph{constant speed} of 40~km/h $\approx 11$~m/s.
The function $h$ defined at the end of the previous section will be used to convert from (distance,speed)
to GPS coordinates.
We also need to be able to add random ``noise'' to these measurements for the simulation, 
which we will later need to use as a distribution $p(\bv_k)$.

We are going to assume that the variability is equal in all directions, therefore we can simplify everything
to a univariate distribution of ``distances'', each associated with a random bearing $\theta\in[0,180)$ 
(negative distances provide the other half of the circle).
Therefore, we can simulate from:
\begin{equation*}
  \bv = 
  \begin{bmatrix}
    d \\ \theta
  \end{bmatrix},\qquad
  \begin{matrix}
    d\sim \mathcal{N}\left(0,\sigma_v^2\right)\\
    \theta \sim \mathcal{U}\left[0,180\right)
  \end{matrix}.
\end{equation*}
We therefore simply add this to our function, as we know how to add a certain distance to a GPS 
coordinate with initial bearing (\S~2.1.4). Thus,
\begin{equation}
  \label{eq:observation_}
  \by_k = \bY_k + \bv_k,
\end{equation}
where ``addition'' is of a (distance, bearing) to a GPS coordinate.


\subsubsection{Data Generation}

Let's create some mock data:
<<constant_speed_mock>>=
t <- seq(1:10) * 60  # time in minutes * 60 = seconds
n <- length(t)

Xtrue <- rbind(t * 11, 11)
Ytrue <- apply(Xtrue, 2, h, shape = shape1)

v <- rbind(rnorm(n, 0, 50), runif(n, 0, 180))
y <- sapply(1:n, function(i) partialSegment(Ytrue[, i], v[2, i], v[1, i]))

thePlot3 <- function(x1, x2) {
    plotShape(shapeIDs[1, 1], con)
    if (!missing(x1)) points(x1[1, ], x1[2, ], pch = 3, col = "#00009930")
    if (!missing(x2)) points(x2[1, ], x2[2, ], pch = 3, cex = 0.5, col = "#00990070")
    points(Ytrue[1, ], Ytrue[2, ], pch = 19, col = "red", cex = 0.5)
    points(y[1, ], y[2, ], pch = 19, cex = 0.6)
}
thePlot3()
@ 


\subsubsection{Likelihood}

We need a likelihood for the observation. We will continue on with our assumption of equal distances,
and therefore simply model the distances, $d_k$, between the particles and the observation.
We can just use the function from before (ignoring direction).
For consistency, we will use $\sigma_v = 50$ as in the simulation;
in practice, we should be able to estimate the accuracy either from the GPS model,
or more likely by computing the ``distance from the road'' of GPS observations.
<<lhood_GPS>>=
lhood <- function(y, x, shape)
    dnorm(distanceFlat(y, h(x, shape = shape)), 0, sd = 50)
@ 


\subsubsection{Simulation}

We'll use the same equations as in \S~1.1 (random acceleration), and the same prior on $x_0$:
<<simulation_init,cache=TRUE>>=
## random error on particles:
pw <- function(n)
    rnorm(n, 0, 0.05)
Delta <- 60 ## seconds
A <- cbind(c(1, 0), c(Delta, 1))
G <- rbind(Delta^2/2, Delta)
fn <- function(x, w)
    structure(A %*% x + G %*% w, .Dimnames = list(c("distance", "speed"), NULL))

N <- 300 ## particles
x0 <- t(rmvnorm(N, c(0, 5), diag(c(0, 50)))) # should really just use rbind(0, rnorm()) ...

x1hat <- fn(x0, pw(N))
hx1hat <- apply(x1hat, 2, h, shape = shape1)

weights <- apply(x1hat, 2, function(xi) lhood(y[, 1], xi, shape1))
qi <- weights / sum(weights)
ii <- sample(N, N, TRUE, qi)
x1 <- x1hat[, ii]
hx1 <- apply(x1, 2, h, shape = shape1)

thePlot3(hx1hat, hx1)
@ 

And, yes, now all of them!

<<simulation__all,fig.width=8,fig.height=8,cache=TRUE>>=
par(mfrow = c(3, 3))
xx <- x1
M <- length(t)
xxhat.hist <- xx.hist <- array(NA, c(2, N, M))
xxhat.hist[,,1] <- x1hat
xx.hist[,,1] <- x1
system.time({
    for (i in 2:M) {
        xxhat.hist[,,i] <- xxhat <- fn(xx, pw(N))
        weights <- apply(xxhat, 2, function(xi) lhood(y[, i], xi, shape1))
        qi <- weights / sum(weights)
        ii <- sample(N, N, TRUE, qi)
        xx.hist[,,i] <- xx <- xxhat[, ii]
        hxxhat <- apply(xxhat, 2, h, shape = shape1)
        
        hxx <- apply(xx, 2, h, shape = shape1)
        thePlot3(hxxhat, hxx)
    }
})

rowMeans(xx)
@ 

So, about 0.15~s to analyse one data point. In R. Without any thoughts having gone into making
things efficient.


\subsubsection{Variable Speed and Irregular Time Observations}

This is easy to generalise, as we make no assumption about the frequency of observations;
we fixed $\Delta = 60$~s in the above example, but this could easily be adjusted for each observation.

To get starting, we are simply going to use the schedule information for a trip as the ``observed
data'', and see how the model performs.
<<get_sched_data>>=
all.trips <- dbGetQuery(con, sprintf("SELECT DISTINCT trip_id FROM trips WHERE shape_id='%s'", shapeIDs[1,1]))
trip1 <- all.trips[1,1]
sched1 <- dbGetQuery(
    con, 
    sprintf("SELECT st.arrival_time AS arrive, st.departure_time AS depart, st.stop_id, 
                    s.stop_lat, s.stop_lon, st.shape_dist_traveled AS distance
             FROM stop_times AS st, stops AS s 
             WHERE trip_id='%s' AND st.stop_id=s.stop_id", trip1))
head(sched1)
@ 

We don't actually need the \emph{distance} column right now---this will be used later when computing 
which stop interval the bus is in. What we do need is to condense it down into unique time observations
(currently, there are several stops at each ``minute'').
We will take the first of each, and take the departure time (or arrival if its missing);
we will also convert times into seconds since the route began.
<<manip_data>>=
library(lubridate)
sched1$time <- hms(ifelse(is.na(sched1$depart), sched1$arrive, sched1$depart))
sched1$time_seconds <- (hour(sched1$time) * 60 + minute(sched1$time)) * 60
sched1$time <- sched1$time_seconds - min(sched1$time_seconds)
data <- do.call(
    rbind, 
    tapply(1:nrow(sched1), sched1$time, 
           function(x) sched1[x[1], c("time", "stop_id", "stop_lat", "stop_lon"), ]))
data[1:3, ]
t <- data$time
y <- rbind(data$stop_lon[-1], data$stop_lat[-1])
@ 

And now we just apply the simulation, but allow for differing $\Delta$:
<<simulation_init_sched,cache=TRUE>>=
## random error on particles:
pw <- function(n)
    rnorm(n, 0, 0.03)
Delta <- diff(t) ## seconds
A <- function(d) cbind(c(1, 0), c(d, 1))
G <- function(d) rbind(d^2/2, d)
fn <- function(x, u, w)  ## x: [distance, velocity]; u: [delta]; w: [error]
    structure(A(u) %*% x + G(u) %*% w, .Dimnames = list(c("distance", "speed"), NULL))

thePlot4 <- function(x1, x2) {
    plotShape(shapeIDs[1, 1], con)
    if (!missing(x1)) points(x1[1, ], x1[2, ], pch = 3, col = "#00009930")
    if (!missing(x2)) points(x2[1, ], x2[2, ], pch = 3, cex = 0.5, col = "#00990070")
    #points(Ytrue[1, ], Ytrue[2, ], pch = 19, col = "red", cex = 0.5)
    points(y[1, ], y[2, ], pch = 19, cex = 0.6)
}

lhood2 <- function(y, x, shape)
    dnorm(distanceFlat(y, h(x, shape = shape)), 0, sd = 50) * ifelse(x[2] <= 0, 0.000001, 1)

N <- 500 ## particles
x0 <- t(rmvnorm(N, c(0, 5), diag(c(0, 50)))) # should really just use rbind(0, rnorm()) ...

x1hat <- fn(x0, Delta[1], pw(N))
hx1hat <- apply(x1hat, 2, h, shape = shape1)

weights <- apply(x1hat, 2, function(xi) lhood2(y[, 1], xi, shape1))
qi <- weights / sum(weights)
ii <- sample(N, N, TRUE, qi)
x1 <- x1hat[, ii]
hx1 <- apply(x1, 2, h, shape = shape1)

thePlot4(hx1hat, hx1)
@ 

And, yes, now all of them!

<<simulation_sched_all,fig.width=8,fig.height=5,cache=TRUE>>=
par(mfrow = c(1, 3))
xx <- x1
M <- length(Delta)
xxhat.hist <- xx.hist <- array(NA, c(2, N, M))
xxhat.hist[,,1] <- x1hat
xx.hist[,,1] <- x1
system.time({
    for (i in 2:M) {
        xxhat.hist[,,i] <- xxhat <- fn(xx, Delta[i], pw(N))
        weights <- apply(xxhat, 2, function(xi) lhood2(y[, i], xi, shape1))
        qi <- weights / sum(weights)
        ii <- sample(N, N, TRUE, qi)
        xx.hist[,,i] <- xx <- xxhat[, ii]
        hxxhat <- apply(xxhat, 2, h, shape = shape1)
        
        hxx <- apply(xx, 2, h, shape = shape1)
        thePlot4(hxxhat, hxx)
    }
})
rowMeans(xx)
@ 

How about speed over  time?
<<>>=
speedhat.hist <- xxhat.hist[2,,]
speed.hist <- xx.hist[2,,]
plot(NA, xlim = range(t), ylim = range(speed.hist, speedhat.hist),
     xlab = "Time (s)", ylab = "Speed (m/s)")
abline(h = 0, lty = 3)
for (i in 1:M) {
    points(rep(t[i+1], N), speedhat.hist[, i], pch = 4, col = "#00009930")
    points(rep(t[i+1], N), speed.hist[, i], pch = 4, cex = 0.5, col = "#00990070")
}
@ 

From that, it looks like we need to put a positive-speed constraint on the proposal distribution;
however, we also need to change the way we view \emph{speed}: it will not be an unknown, fairly
constant variable. Instead, we will use as much information as is avaialble to us to esimate the
speed along each segment of road.


<<>>=
speedhat <- as.numeric(speedhat.hist)
speed <- as.numeric(speed.hist)
disthat <- as.numeric(xxhat.hist[1,,])
dist <- as.numeric(xx.hist[1,,])

plot(disthat, speedhat, pch = 3, col = "#00009930",
     xlim = range(dist, disthat), ylim = range(speed, speedhat),
     xlab = "Distance (m)", ylab = "Speed (m/s")
points(dist, speed, pch = 3, cex = 0.5, col = "#00990070")

@ 



\section{MBTA GTFS Realtime Feed}

Thankfully, we can get some data! The connection to the database is:
<<mbta_connection>>=
mbta <- dbConnect(SQLite(), "mbta_gtfsrt.db")
@ 

And the historical data can be sorted through nicely:
<<location_history,cache=TRUE>>=
hist <- dbGetQuery(
    mbta, "SELECT v.trip_id, t.shape_id, COUNT(v.trip_id) AS n
           FROM vehicle_positions AS v, 
                trips AS t, routes AS r
           WHERE v.trip_id=t.trip_id
             AND t.route_id=r.route_id
             AND r.route_type=3
           GROUP BY v.trip_id ORDER BY n DESC")
head(hist)
@ 

So, trip \verb+\Sexpr{hist[1,1]}+ looks pretty popular. We'll get some useful information for that.
<<trip_route_info>>=
tID <- hist[1, "trip_id"]
sID <- hist[1, "shape_id"]
plotShape(sID, mbta)
@ 


\subsection{Data Sorting}

We've first got to sort through the data. We will start at the beginning (the first trip) and work
our way through---hopefully we will be able to start generating priors and stuff!

<<data_sorting1,cache=TRUE>>=
# Get all days
all.dates <- dbGetQuery(
    mbta,
    sprintf("SELECT DISTINCT trip_start_date FROM vehicle_positions WHERE trip_id='%s'",
            tID))
(dates <- all.dates$trip_start_date)
@ 

We now need a function to obtain all of the necessary data for a trip on a given day:
<<data_trip_day>>=
getTripData <- function(date, id, conn = con) {
    d <- dbGetQuery(conn,
                    sprintf("SELECT position_latitude AS lat, position_longitude AS lon,
                                    timestamp AS time
                             FROM vehicle_positions
                             WHERE trip_id='%s' AND trip_start_date='%s'
                             ORDER BY timestamp", id, date))
    attr(d, "date") <- date
    attr(d, "trip_id") <- id
    class(d) <- c("triphistory", class(d))
    d
}
print.triphistory <- function(x, ...) {
    print.data.frame(x)
}
points.triphistory <- function(x, ...) {
    points(x$lon, x$lat, col = "red", cex = 0.5, pch = 4)
}
@

So, on the first day:
<<first_day,cache=TRUE>>=
day1 <- getTripData(dates[1], tID, mbta)
head(day1)

tripShape <- plotShape(sID, mbta)
points(day1)
@ 

So, it's obvious that some points don't belong to the trip---they are of where the bus went
before/after it started/finished (we won't worry about them for now).

\subsection{A Particle Filter Modelling Function}

Previously we've just copy+pasted the necessary code. Now we'll make a function to do it moreorless properly.
<<PF_function>>=
particleFilter <- function(data, shape,
                           N = 200,
                           zero.start = TRUE,
                           x0 = if (zero.start) rbind(0, rlnorm(N, 0, 2)) 
                                else rbind(runif(0, max(shape$distance), N),
                                           rlnorm(N, 0, 2)),
                           GPS.error = 20,
                           sig.e = 0.03,
                           ...) {
    ## Sort out the shape information (using previously defined functions)
    z <- t(shape[, 1:2])
    di <- distanceFlat(z[, -ncol(z)], z[, -1])
    shape$distance <- c(0, cumsum(di))
    shape$length <- c(di, NA)
    shape$bearing <- c(bearing(z[, -ncol(z)], z[, -1]), NA)
    shape <- shape[shape$length > 0 | is.na(shape$length), ]
        
    ## Preparation (redefining all functions):
    h <- function(x) {
        if (x[1] <= 0) return(c(0, 0))
        if (x[1] > max(shape$distance)) return(as.numeric(shape[nrow(shape), 1:2]))
        j <- which.min(x[1] > shape$distance) - 1
        sj <- shape[j, ]
        Psi <- sj$bearing
        d <- x[1] - sj$distance
        
        ## only do the calculations if we need to!
        if (d == 0) return(as.numeric(sj[1:2]))
        partialSegment(as.numeric(sj[1:2]), Psi, d)
    }
    ## The likelihood:
    lhood <- function(y, x)
        dnorm(distanceFlat(y, h(x)), 0, sd = GPS.error) *
            ifelse(x[2] <= 0, 0.000001, 1)
    ## The random component:
    pw <- function(n)
        rnorm(n, 0, sig.e)
    
    ## The formal model ... will definitely change!!!
    A <- function(d) cbind(c(1, 0), c(d, 1))
    G <- function(d) rbind(d^2/2, d)
    fn <- function(x, u, w) ## x: [distance, velocity]; u: [delta]; w: [error]
        structure(A(u) %*% x + G(u) %*% w, 
                  .Dimnames = list(c("distance", "speed"), NULL))
    
    ## Data prep:
    y <- rbind(data$lon, data$lat)
    t <- data$time
    Delta <- diff(t)
    M <- length(Delta)  ## the number of "true" observations...?
    
    ## Matrix prep:
    hx <- hxhat <- xxhat <- xx <- array(NA, c(2, N, M + 1))
    
    ## Initialise:
    xx[,,1] <- x0
    
    ## run the simulations
    for (i in 1:M) {
        xxhat[,,i+1] <- fn(xx[,,i], Delta[i], pw(N))
        weights <- apply(xxhat[,,i+1], 2, function(xi) lhood(y[,i+1], xi))
        qi <- weights / sum(weights)
        if (any(is.na(qi)))
            qi <- NULL
            
        ii <- sample(N, N, TRUE, qi)
        xx[,,i+1] <- xxhat[,ii,i+1]
        
        hxhat[,,i+1] <- apply(xxhat[,,i+1], 2, h)
        hx[,,i+1] <- apply(xx[,,i+1], 2, h)
    }
    
    res <- list(Xhat = xxhat, 
                X = xx, 
                HXhat = hxhat, 
                HX = hx,
                y = y, t = t, M = M, N = N)
    class(res) <- "pf.fit"
    
    res
}

plot.pf.fit <- function(x, shape.id, obs = 1, conn = con) {
    plotShape(sID, conn)
    points(x$HXhat[1,,obs], x$HXhat[2,,obs], pch = 4, col = "#00009930")
    points(x$HX[1,,obs], x$HX[2,,obs], pch = 4, cex = 0.5, col = "#00990070")
    points(x$y[1,obs], x$y[2,obs], col = "red", pch = 19, cex = 0.4)
}
@ 

\subsection{Modelling the First Day}

<<first_day_model,cache=TRUE>>=
## by manual inspection, filter only observations that occur on the route:
day1onroute <- day1[5:17, ]
day1.results <- particleFilter(day1onroute, tripShape)
@ 

<<plot_first_day,fig.width=9,fig.height=10>>=
par(mfrow = c(3, 2))
for (i in 1:day1.results$M)
    plot(day1.results, sID, i+1, mbta)
@ 

Clearly, the randomness isn't corrently being modelled---but this makes sense! We are using a
Newtonian dynamics model, but that doesn't really apply to a bus that is stopping and starting at
bus stops! We should be taking into account
\begin{enumerate}
\item the (typical) time taken to travel from stop $i$ to stop $i+k$, and
\item the dwell time at stops $i,i+1,\ldots,i+k-1$.
\end{enumerate}


\subsection{Remaining Days}


<<days_data,cache=TRUE,fig.height=10,out.width="0.8\\textwidth">>=
par(mfrow = c(4, 2))

days <- lapply(2 :9, function(i) getTripData(dates[i], tID, mbta))
invisible(lapply(days, function(day) {
    plotShape(sID, mbta)
    points(day)
}))
@ 

It looks like the ``trip ID'' being reported isn't updating correctly.
The best way around this would be to instead of ``block ID'' and decide for ourselves which trip the
bus is on.
However, the current state of the Auckland GTFS doesn't suppy block IDs to routes, so its difficult
(if not impossible) to obtain this information. 

If we were, however, to break away from our Newtonian physics based model, and instead use some
prior knowledge about speed at a given distance into a trip, we should be able to make use of the
``half'' data sets.



\section{Block and Trips}

From the MBTA feed we can get block information, so:
<<block_day_functions>>=
getShape <- function(id, conn, include.id = FALSE) {
    sh <- dbGetQuery(conn, 
                     sprintf("SELECT shape_pt_lon AS lon, shape_pt_lat AS lat
                              FROM shapes WHERE shape_id='%s'", id))
    if (include.id)
        sh$shape_id <- id
    
    class(sh) <- c("gtfs.shape", class(sh))
    sh
}
plot.gtfs.shape <- function(x, add = FALSE, ...) {
    if (add)
        lines(x$lon, x$lat, ...)
    else
        plot(x$lon, x$lat, type = "l", asp = 1,
             xlab = "Longitude", ylab = "Latitude", ...)
    
    points(x$lon[1], x$lat[1], pch = 19, ...)
}

getBlock <- function(id, conn) {
    blockInfo <- dbGetQuery(
        conn,
        sprintf("SELECT t.block_id, t.trip_id, t.route_id, t.shape_id, s.departure_time
                 FROM trips AS t, stop_times AS s 
                 WHERE block_id='%s' 
                   AND t.trip_id=s.trip_id AND s.stop_sequence=1
                 ORDER BY s.departure_time", 
                bID))
    
    blockShapes <- lapply(unique(blockInfo$shape_id),
                          function(id) getShape(id, conn, include.id = TRUE))
    names(blockShapes) <- unique(blockInfo$shape_id)
    class(blockShapes) <- c("gtfs.block.shapes")
    
    fullPath <- do.call(rbind, blockShapes[blockInfo$shape_id])
    blockPath <- data.frame(lon = fullPath$lon, lat = fullPath$lat)
    class(blockPath) <- c("gtfs.shape", class(blockPath))
    
    schedule <- dbGetQuery(
        conn,
        sprintf("SELECT trip_id, stop_id, stop_sequence,
                        CASE WHEN arrival_time IS NULL 
                          THEN departure_time 
                          ELSE arrival_time END AS time,
                        shape_dist_traveled
                 FROM stop_times WHERE trip_id IN ('%s') 
                 ORDER BY time, stop_sequence",
                paste(blockInfo$trip_id, collapse = "','"))
    )
    
    out <- list(trips = blockInfo,
                shapes = blockShapes,
                path = blockPath,
                schedule = schedule)
    
    class(out) <- c("gtfs.block")
    out
}
print.gtfs.block <- function(x, ...) {
    print(x$trips)
}
head.gtfs.block <- function(x, n = 6, ...)
    head(x$trips, n, ...)
plot.gtfs.block <- function(x, highlight = 1, ...)
    plot.gtfs.block.shapes(x$shapes[x$trips$shape_id], highlight = highlight, ...)
plot.gtfs.block.shapes <- function(x, highlight = 1, ...) {
    # plot ALL of the shapes...
    all <- do.call(rbind, x)

    plot(NA, type = "n", asp = 1,
         xlim = range(all$lon), ylim = range(all$lat),
         xlab = "Longitude", ylab = "Latitude",
         main = paste("Highlighting route", highlight))
    
    for (i in 1:length(x)) {
        if (highlight[1] == i)
            plot(x[[i]], add = TRUE, col = "#ff000050", lwd = 3)
        else
            plot(x[[i]], add = TRUE, lty = 3, cex = 0.6)
    }
}
@ 

<<block_dat_example,cache=TRUE>>=
blockID <- dbGetQuery(mbta,
                        sprintf("SELECT block_id
                                 FROM trips WHERE trip_id='%s'", tID))
bID <- blockID$block_id
block <- getBlock(bID, mbta)
head(block)
plot(block)
@ 

We can see that a ``block'' consists of a lot of very similar routes (in this case, anyway).
So, instead of obtaining data for the same \emph{trip}, we could just grab a days worth of data for
a block, like this:
<<day_block_data,cache=TRUE>>=
getBlockData <- function(date, id, block, conn) {
    if (missing(block))
        block <- getBlock(id, conn)
    
    d <- dbGetQuery(
        conn,
        sprintf("SELECT position_latitude AS lat, position_longitude AS lon,
                        timestamp AS time, trip_id
                 FROM vehicle_positions
                 WHERE trip_id IN ('%s') AND trip_start_date='%s'
                 ORDER BY timestamp",
                paste0(block$trips$trip_id, collapse = "','"), date))
    
    attr(d, "date") <- date
    attr(d, "trip_id") <- block$trips$trip_id
    
    class(d) <- c("blockhistory", "triphistory", class(d))
    
    if (missing(block))
        return(d)
    else {
        block$history <- d
        return(block)
    }
}
block.history <- getBlockData("20151202", bID, conn = mbta)
@ 

The trouble here is that the model doesn't actually know where it is, and gets completely and
utterly lost, so we need some method for limiting where it can be---queue static timetable in GTFS.


\subsection{Static Schedule GTFS}

It appears that the MBTA ``block\_id'' is messed up; it's not giving a non-overlapping set of trips
that a single bus could run (there are overlapping trips!).
To get around this problem, we will explore historical data for patterns.
<<historical_getexplore,cache=TRUE>>=
history <- dbGetQuery(
    mbta,
    paste0("SELECT DISTINCT vp.trip_id, vp.vehicle_id, vp.trip_start_date, 
                            st.departure_time AS trip_start_time
            FROM vehicle_positions AS vp, stop_times AS st, trips AS tr, routes AS rt
            WHERE vp.trip_id=st.trip_id AND st.stop_sequence=1 
              AND vp.trip_id=tr.trip_id AND tr.route_id=rt.route_id AND rt.route_type=3
            ORDER BY vp.trip_start_date, vp.vehicle_id, trip_start_time")
)
@
<<historical_explore,cache=TRUE>>=
hist.dates <- tapply(1:nrow(history), history$trip_start_date,
                     function(i) history[i, ])

hist.blocks <- lapply(hist.dates, function(h) {
    tapply(1:nrow(h), h$vehicle_id, function(i) h[i, ])
})
@ 


We can get one day of data for a vehicle:
<<manual_blocking,fig.width=10,fig.height=12,out.width="0.8\\textwidth">>=
blockA <- hist.blocks[[2]][[2]]
#blockA <- hist.blocks[[3]][["y6010"]]
getBlockAlt <- function(ids, date, conn) {
    blockInfo <- dbGetQuery(
        conn,
        sprintf("SELECT t.trip_id, t.route_id, t.shape_id, s.departure_time
                 FROM trips AS t, stop_times AS s 
                 WHERE t.trip_id IN ('%s')
                   AND t.trip_id=s.trip_id AND s.stop_sequence=1
                 ORDER BY s.departure_time", 
                paste0(ids, collapse = "','")))
    
    blockShapes <- lapply(unique(blockInfo$shape_id),
                          function(id) getShape(id, conn, include.id = TRUE))
    names(blockShapes) <- unique(blockInfo$shape_id)
    class(blockShapes) <- c("gtfs.block.shapes")
    
    fullPath <- do.call(rbind, blockShapes[blockInfo$shape_id])
    blockPath <- data.frame(lon = fullPath$lon, lat = fullPath$lat,
                            trip_id = rep(blockInfo$trip_id, 
                                sapply(blockShapes[blockInfo$shape_id], nrow)))
    class(blockPath) <- c("gtfs.shape", class(blockPath))
    
    schedule <- dbGetQuery(
        conn,
        sprintf("SELECT trip_id, stop_id, stop_sequence,
                        CASE WHEN arrival_time IS NULL 
                          THEN departure_time 
                          ELSE arrival_time END AS time,
                        shape_dist_traveled
                 FROM stop_times WHERE trip_id IN ('%s') 
                 ORDER BY time, stop_sequence",
                paste(blockInfo$trip_id, collapse = "','"))
    )
    
    out <- list(trips = blockInfo,
                shapes = blockShapes,
                path = blockPath,
                schedule = schedule, 
                date = date)
    
    class(out) <- c("gtfs.block")
    out
}

block <- getBlockAlt(blockA$trip_id, blockA$trip_start_date[1], mbta)
par(mfrow = c(4, 2))
for (i in 1:nrow(block$trips))
    plot(block, highlight = i)
@ 

Now THAT looks much better! Let's get the data:

<<manual_block_data,cache=TRUE>>=
points.gtfs.block <- function(block, ...)
    with(block$history, points(lon, lat, pch = 4, col = "#ff000070", cex = 0.6))
block <- getBlockData(block$date, block = block, conn = mbta)
plot(block, highlight = FALSE)
points(block)
@ 


Alright, so let's just cross our fingers and apply the particle filter!

<<manual_block_particleFilter,cache=TRUE>>=
blockPF <- function(block, zero.start = TRUE, start.obs = 1, ...) {
    pf <- particleFilter(block$history[start.obs:nrow(block$history), ], 
                         block$path, zero.start = zero.start, ...)
    pf$block <- block    
    class(pf) <- c("pf.blockfit")
    pf
}
plot.pf.blockfit <- function(x, obs = 1, highlight = FALSE) {
    plot(x$block, highlight = highlight)
    points(x$HXhat[1,,obs], x$HXhat[2,,obs], pch = 4, col = "#00009930")
    points(x$HX[1,,obs], x$HX[2,,obs], pch = 4, cex = 0.5, col = "#00990070")
    points(x$y[1,obs], x$y[2,obs], col = "red", pch = 19, cex = 0.4)
}

pfit <- blockPF(block, start.obs = 1)
@ 

<<manual_fit_explore>>=
plot(pfit, obs = 30, highlight = 2)
@ 

Matching is wrong. Need to restrict distance by time.


\subsection{Restricting Distance into Trip by Schedule Time}

<<modified_pf_function,cache=TRUE>>=
pf2 <- function(block,
                N = 200,
                zero.start = TRUE,
                start.obs = 1,
                x0 = if (zero.start) rbind(0, rlnorm(N, 0, 2)) 
                     else rbind(runif(0, max(shape$distance), N),
                                rlnorm(N, 0, 2)),
                GPS.error = 20,
                sig.e = 0.03,
                progress = FALSE,
                ...) {
    shape <- block$path
    data <- block$history[start.obs:nrow(block$history), ]
    trips <- block$trips
    trips$end_time <- hms(c(trips$departure_time[-1]), tz = "EST5EDT")
    
    ## Sort out the shape information (using previously defined functions)
    z <- t(shape[,1:2])
    di <- distanceFlat(z[, -ncol(z)], z[, -1])
    shape$distance <- c(0, cumsum(di))
    shape$length <- c(di, NA)
    shape$bearing <- c(bearing(z[, -ncol(z)], z[, -1]), NA)
    shape <- shape[shape$length > 0 | is.na(shape$length), ]
        
    ## Preparation (redefining all functions):
    h <- function(x) {
        if (x[1] <= 0) return(c(0, 0))
        if (x[1] > max(shape$distance)) return(as.numeric(shape[nrow(shape), 1:2]))
        j <- which.min(x[1] > shape$distance) - 1
        sj <- shape[j, ]
        Psi <- sj$bearing
        d <- x[1] - sj$distance
        
        ## only do the calculations if we need to!
        if (d == 0) return(as.numeric(sj[1:2]))
        partialSegment(as.numeric(sj[1:2]), Psi, d)
    }
    ## ------------------------------------------------- The likelihood ##
    lhood <- function(y, x) {
        # y: GPS observation
        # x: a distance-into-trip
        dnorm(distanceFlat(y, h(x)), 0, sd = GPS.error) * 
            ifelse(x[2] <= 0, 0.000001, 1)

    }
    ## The random component:
    pw <- function(n)
        rnorm(n, 0, sig.e)
    
    ## The formal model ...
    ## Needs to account for schedule times.
    ## For starters, just restrict to start of trip time.
    ## ---------------------------------------------------------------- ##
    A <- function(d) cbind(c(1, 0), c(d, 1))
    G <- function(d) rbind(d^2/2, d)
    fn <- function(x, u, t, w) { ## x: [distance, velocity]; u: [delta, time]; w: [error]
        X <- structure(A(u) %*% x + G(u) %*% w, 
                       .Dimnames = list(c("distance", "speed"), NULL))
        
        tid <- trips$trip_id[which(trips$end_time > t)[1]]
        if (is.na(tid))
            return(X)
        Xmax <- max(shape[shape$trip_id == tid, "distance"])
        X <- apply(X, 2, function(x) if (x[1] > Xmax) c(Xmax, 0) else x)
        X[2, ] <- ifelse(X[2, ] < 0, 0, X[2, ])
        
        X
    }
    
    ## Data prep:
    y <- rbind(data$lon, data$lat)
    t <- data$time
    TIME <- lubridate::hms(format(as.POSIXct(data$time, origin="1970-01-01", tz="EST5EDT"), "%H:%M:%S"),
                           tz = "EDT5EDT")
    Delta <- diff(t)
    M <- length(Delta)  ## the number of "true" observations...?
    
    ## Matrix prep:
    hx <- hxhat <- xxhat <- xx <- array(NA, c(2, N, M + 1))
    
    ## Initialise:
    xx[,,1] <- x0
    
    ## run the simulations
    if (progress) {
        suppressMessages({library(R.utils)})
        pb <- txtProgressBar(min = 0, max = M, style = 3)
    }
    for (i in 1:M) {
        xxhat[,,i+1] <- fn(xx[,,i], Delta[i], TIME[i+1], pw(N))
        weights <- apply(xxhat[,,i+1], 2, function(xi) lhood(y[,i+1], xi))
        qi <- weights / sum(weights)
        if (any(is.na(qi)))
            qi <- NULL
            
        ii <- sample(N, N, TRUE, qi)
        xx[,,i+1] <- xxhat[,ii,i+1]
        
        hxhat[,,i+1] <- apply(xxhat[,,i+1], 2, h)
        hx[,,i+1] <- apply(xx[,,i+1], 2, h)
        if (progress) setTxtProgressBar(pb, i)
    }
    if (progress) close(pb)
    
    res <- list(Xhat = xxhat, 
                X = xx, 
                HXhat = hxhat, 
                HX = hx,
                y = y, t = t, M = M, N = N,
                block = block)
    class(res) <- "pf.blockfit"
    
    res
}

fit <- pf2(block, start.obs = 1)
@ 

<<plot_new_fit,fig.width=10,fig.height=12,out.width="0.8\\textwidth",cache=TRUE>>=
unlink("FIGS/anim*.jpg")
jpeg("FIGS/anim%04d.jpg", width = 400, height = 300)
for(i in 2:length(fit$HX[1,1,]))
    plot(fit, i)
dev.off()
unlink("figure/animated_block_history.gif")
system("convert -delay 1 FIGS/anim*.jpg figure/animated_block_history.gif")
unlink("FIGS/*.jpg")
@ 

So, few issues. First, once the bus reaches the end of a trip, the speed is reset to 0, and so it's
stuck and takes a while to get moving again---in the meantime, the particle get lagged behind the
bus, so the speed goes way too fast and overshoots the bus.
Second, the bus is stuck at the END of a route, not the beginning of the next one.


\subsection{Using Schedule as Speed Function}

We have so far been using a very primitive Newtonian physics model for the state $X$ model.
However, this breaks down when the bus ``stops'' at the end/beginning of a route waiting for the
scheduled departure time.
Overall, we want to move away from this type of model, and instead use real data to model the speed
along segments.
The first step will be to work on a ``prior'' speed model, which we will for now base on the
scheduled arrival and departure times at the stops along the route.

The speed function will be computed by a smooth polynomial spline fitted through the scheduled
arrival times.
For this, we need to know the distance-into-trip of the stops in a trip.
Using the previous example, we can use the first trip's schedule to demonstrate:

<<shape_of_first_trip,cache=TRUE>>=
getShapeDist <- function(sched, sh) {
    ## DRY - need a function for this ... or just to it in getBlock ...
    z <- t(sh[,1:2])
    di <- distanceFlat(z[, -ncol(z)], z[, -1])
    sh$distance <- c(0, cumsum(di))
    sh$length <- c(di, NA)
    sh$bearing <- c(bearing(z[, -ncol(z)], z[, -1]), NA)
    sh <- sh[sh$length > 0 | is.na(sh$length), ]
    
    ## Convert to FLAT XY
    sh$lam <- sh$lon * pi / 180
    sh$phi <- sh$lat * pi / 180
    sched$lam <- sched$stop_lon * pi / 180
    sched$phi <- sched$stop_lat * pi / 180
    
    phi1 <- mean(sh$phi)
    sh$x <- sh$lam * cos(phi1)
    sh$y <- sh$phi
    sched$x <- sched$lam * cos(phi1)
    sched$y <- sched$phi
    
    #plot(sh$x, sh$y, type = "l", asp = 1)
    
    d <- numeric(nrow(sched))
    J <- 1
    nr <- nrow(sh)
    nr1 <- nr - 1
    for (i in 1:nrow(sched)) {
        p <- as.numeric(sched[i, c("x", "y")])
        
        di <- ri <- numeric(nr - J)
        pxy <- matrix(NA, nrow = nr - J, ncol = 2)
        for (j in J:nr1) {
            ji <- j - J + 1
            q1 <- as.numeric(sh[j, c("x", "y")])
            q2 <- as.numeric(sh[j + 1, c("x", "y")])
            
            v <- q2 - q1
            w <- p - q1
        
            wv <- w %*% v
            vv <- v %*% v
            ww <- w %*% w
                        
            if (wv < 0) {
                r2 <- ww
                di[ji] <- 0
                ri[ji] <- sqrt(r2)
            } else if (wv <= vv) {
                d2 <- wv^2 / vv
                r2 <- ww - d2
                ri[ji] <- sqrt(r2)
                di[ji] <- sqrt(d2)
            } else {
                r2 <- (w - v) %*% (w - v)
                d2 <- vv
                ri[ji] <- sqrt(r2)
                di[ji] <- sqrt(d2)
            }
            
            pxy[ji, ] <- q1 + di[ji] / sqrt(vv) * v
        }
        
        wi <- which.min(ri)
        J <- J + wi - 1
        
        ## convert it:
        ## points(pxy[1], pxy[2], cex = 0.5, pch = 4, col = "blue")
        pll <- c(pxy[wi, 1] / cos(phi1), pxy[wi, 2]) * 180 / pi
        d[i] <- sh[J, "distance"] + distanceFlat(pll, as.numeric(sh[J, c("lon", "lat")]))
    }

    d
}

getBlock <- function(ids, date, conn) {
    blockInfo <- dbGetQuery(
        conn,
        sprintf("SELECT t.trip_id, t.route_id, t.shape_id, s.departure_time
                 FROM trips AS t, stop_times AS s 
                 WHERE t.trip_id IN ('%s')
                   AND t.trip_id=s.trip_id AND s.stop_sequence=1
                 ORDER BY s.departure_time", 
                paste0(ids, collapse = "','")))
    
    blockShapes <- lapply(unique(blockInfo$shape_id),
                          function(id) getShape(id, conn, include.id = TRUE))
    names(blockShapes) <- unique(blockInfo$shape_id)
    class(blockShapes) <- c("gtfs.block.shapes")
    
    fullPath <- do.call(rbind, blockShapes[blockInfo$shape_id])
    blockPath <- data.frame(lon = fullPath$lon, lat = fullPath$lat,
                            trip_id = rep(blockInfo$trip_id, 
                                sapply(blockShapes[blockInfo$shape_id], nrow)))
    class(blockPath) <- c("gtfs.shape", class(blockPath))
    
    ## Get the position of the stops
    schedule <- dbGetQuery(
        conn,
        sprintf("SELECT st.trip_id, st.stop_id, st.stop_sequence,
                        s.stop_lat, s.stop_lon,
                        CASE WHEN st.arrival_time IS NULL 
                          THEN st.departure_time 
                          ELSE st.arrival_time END AS time,
                        st.shape_dist_traveled
                 FROM stop_times AS st, stops AS s
                 WHERE st.stop_id=s.stop_id AND trip_id IN ('%s') 
                 ORDER BY time, stop_sequence",
                paste(blockInfo$trip_id, collapse = "','"))
    )
    
    ## Compute distance into trip:
    if (any(is.na(schedule$shape_dist_traveled))) {
        sdt <- lapply(unique(schedule$trip_id), function(id)
            getShapeDist(schedule[schedule$trip_id == id, ],
                         blockShapes[[blockInfo[blockInfo$trip_id == id, "shape_id"]]]))
        schedule$shape_dist_traveled <- do.call(c, sdt)
    }
    
    ## Compute speed functions:
    speedFns <- tapply(1:nrow(schedule), schedule$trip_id,
                       function(id) {
                           x <- schedule$shape_dist_traveled[id]
                           t <- hms(schedule$time[id])
                           tt <- (hour(t) * 60 + minute(t)) * 60
                           t0 <- tt - min(tt)
                           yy <- unique(t0)
                           xx <- tapply(x, t0, min)
                           
                           splinefun(xx, yy)
                       })
    
    
    out <- list(trips = blockInfo,
                shapes = blockShapes,
                path = blockPath,
                schedule = schedule, 
                speed = speedFns,
                date = date)
    
    class(out) <- c("gtfs.block")
    out
}

block.speed <- getBlock(blockA$trip_id, blockA$trip_start_date[1], mbta)
block.speed <- getBlockData(block.speed$date, block = block.speed, conn = mbta)
@ 

So now each trip has a ``speed'' function computed. In actual fact, the function is
``scheduled time at distance $x$ into trip'', the derivative of which gives us speed:
<<speed_function_1>>=
fn1 <- block.speed$speed[[1]]
curve(fn1(x), 0, 
      max(block.speed$schedule[block.speed$schedule$trip_id == 
                                   block.speed$trips$trip_id[1], ]$shape_dist_traveled),
      xlab = "Distance (m)", ylab = "Time (s)")
curve(fn1(x, 1), 0, 
      max(block.speed$schedule[block.speed$schedule$trip_id == 
                                   block.speed$trips$trip_id[1], ]$shape_dist_traveled),
      xlab = "Distance (m)", ylab = "Speed (m/s)")
@ 

Now, we need to incorporate this into the model ... but how?


\subsection{Incorporating Speed in the Model}

We need something like
\begin{equation}
  \label{eq:speed_model_required}
  \bx_k = A_k \bx_{k-1} + B_{k-1} \bu_k + G_{k-1} \bw_k
\end{equation}
but now, instead of $\bx$ containing distance into trip and speed, it can contain distance into trip
and some \emph{delay} parameter (running slower or faster than usual?).

Let's start very simply:
\begin{equation*}
  A =
  \begin{bmatrix}
    1 & 0 \\
    0 & 0
  \end{bmatrix},\qquad
  B_k =
  \begin{bmatrix}
    s(d_k) \\ 0
  \end{bmatrix},\quad\text{and}\quad
  \bu_k =
  \begin{bmatrix}
    \Delta_k
  \end{bmatrix},
\end{equation*}


<<speed_particle_filter,cache=TRUE>>=
speedPF <- function(block,
                    N = 200,
                    zero.start = TRUE,
                    start.obs = 1,
                    x0,
                    GPS.error = 20,
                    sig.e = 0.03,
                    progress = FALSE,
                    ...) {
    shape <- block$path
    data <- block$history[start.obs:nrow(block$history), ]
    trips <- block$trips
    trips$end_time <- hms(c(trips$departure_time[-1]), tz = "EST5EDT")
    
    schedule <- block$schedule
    speed <- block$speed
    
    if (missing(x0)) {
        x0 <- c(0, speed[[schedule$trip_id[1]]](0))
    }
    
    ## Sort out the shape information (using previously defined functions)
    z <- t(shape[,1:2])
    di <- distanceFlat(z[, -ncol(z)], z[, -1])
    shape$distance <- c(0, cumsum(di))
    shape$length <- c(di, NA)
    shape$bearing <- c(bearing(z[, -ncol(z)], z[, -1]), NA)
    shape <- shape[shape$length > 0 | is.na(shape$length), ]
        
    ## Preparation (redefining all functions):
    h <- function(x) {
        if (x[1] <= 0) return(c(0, 0))
        if (x[1] > max(shape$distance)) return(as.numeric(shape[nrow(shape), 1:2]))
        j <- which.min(x[1] > shape$distance) - 1
        sj <- shape[j, ]
        Psi <- sj$bearing
        d <- x[1] - sj$distance
        
        ## only do the calculations if we need to!
        if (d == 0) return(as.numeric(sj[1:2]))
        partialSegment(as.numeric(sj[1:2]), Psi, d)
    }
    ## ------------------------------------------------- The likelihood ##
    lhood <- function(y, x) {
        # y: GPS observation
        # x: a distance-into-trip
        dnorm(distanceFlat(y, h(x)), 0, sd = GPS.error) * 
            ifelse(x[2] <= 0, 0.000001, 1)

    }
    ## The random component:
    pw <- function(n)
        rnorm(n, 0, sig.e)
    
    ## The formal model ...
    ## ---------------------------------------------------------------- ##
    A <- function(d) cbind(c(1, 0), c(d, 0))
    B <- function(x) rbind(s(x[1]), 0)
    G <- function(d) rbind(d^2/2, d)
    fn <- function(x, u, t, w) { ## x: [distance, velocity]; u: [delta, time]; w: [error]
        X <- structure(A(u) %*% x + + B(x) %*% u[1] + G(u) %*% w, 
                       .Dimnames = list(c("distance", "speed"), NULL))
        
        tid <- trips$trip_id[which(trips$end_time > t)[1]]
        if (is.na(tid))
            return(X)
        Xmax <- max(shape[shape$trip_id == tid, "distance"])
        X <- apply(X, 2, function(x) if (x[1] > Xmax) c(Xmax, 0) else x)
        X[2, ] <- ifelse(X[2, ] < 0, 0, X[2, ])
        
        X
    }
    
    ## Data prep:
    y <- rbind(data$lon, data$lat)
    t <- data$time
    TIME <- lubridate::hms(format(as.POSIXct(data$time, origin="1970-01-01", tz="EST5EDT"), "%H:%M:%S"),
                           tz = "EDT5EDT")
    Delta <- diff(t)
    M <- length(Delta)  ## the number of "true" observations...?
    
    ## Matrix prep:
    hx <- hxhat <- xxhat <- xx <- array(NA, c(2, N, M + 1))
    
    ## Initialise:
    xx[,,1] <- x0
    
    ## run the simulations
    if (progress) {
        suppressMessages({library(R.utils)})
        pb <- txtProgressBar(min = 0, max = M, style = 3)
    }
    for (i in 1:M) {
        xxhat[,,i+1] <- fn(xx[,,i], Delta[i], TIME[i+1], pw(N))
        weights <- apply(xxhat[,,i+1], 2, function(xi) lhood(y[,i+1], xi))
        qi <- weights / sum(weights)
        if (any(is.na(qi)))
            qi <- NULL
            
        ii <- sample(N, N, TRUE, qi)
        xx[,,i+1] <- xxhat[,ii,i+1]
        
        hxhat[,,i+1] <- apply(xxhat[,,i+1], 2, h)
        hx[,,i+1] <- apply(xx[,,i+1], 2, h)
        if (progress) setTxtProgressBar(pb, i)
    }
    if (progress) close(pb)
    
    res <- list(Xhat = xxhat, 
                X = xx, 
                HXhat = hxhat, 
                HX = hx,
                y = y, t = t, M = M, N = N,
                block = block)
    class(res) <- "pf.blockfit"
    
    res
}

fit <- pf2(block.speed, start.obs = 1)
@ 

<<plot_new_fit2,fig.width=10,fig.height=12,out.width="0.8\\textwidth",cache=TRUE>>=
unlink("FIGS/anim*.jpg")
jpeg("FIGS/anim%04d.jpg", width = 400, height = 300)
for(i in 2:length(fit$HX[1,1,]))
    plot(fit, i)
dev.off()
unlink("figure/animated_block_history2.gif")
system("convert -delay 2 FIGS/anim*.jpg figure/animated_block_history2.gif")
unlink("FIGS/*.jpg")
@ 

\end{document}
